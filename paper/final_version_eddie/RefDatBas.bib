@inproceedings{deepdriving,
    author = "C. Chen and A. Seff and A. Kornhauser and J. Xiao.",
    booktitle = "Proceedings of 15th IEEE International Conference on Computer Vision",
    title = "DeepDriving: Learning Affordance for Direct Perception in Autonomous Driving",
    year = "2015",
}

@article{lstm_hochreiter,
    title="Long Short-Term Memory",
    author="Sepp Hochreiter and Jurgen Schmidhuber",
    year="1997",
    journal="Neural Computation",
    volume="9",
    pages="1735-1780",
}

@phdthesis{hochreiter_analysis,
    title="Untersuchungen zu dynamischen neuronalen Netzen",
    author="Josef Hochreiter",
    year="1991",
    school="Institut fur Informatik Technische Universit¨at Munchen",
}

@article{liew,
    title="Which Lag Length Selection Criteria Should We Employ",
    author="Venus Khim−Sen Liew",
    year="2004",
    journal="Economics Bulletin",
    volume="3",
    number="33",
    pages="1--9"
}

@article{aic_bic1,
    title="Multimodel Inference: Understanding AIC and BIC in Model Selection",
    author="Kenneth P. Burnham and David R. Anderson",
    year="2004",
    journal="Sociologal Methods and Research",
    volume="33",
    number="2",
    pages="261--304"
}

@article{aic_bic2,
    title="AIC and BIC: Comparisons of Assumptions and Performance",
    author="Jouni Kuha",
    year="2004",
    journal="Sociologal Methods and Research",
    volume="33",
    number="2",
    pages="188--229"
}

@article{mars,
    title="Multivariate Adaptive Regression Splines",
    author="Jerome H. Friedman",
    year="1991",
    journal="The Annals of Statistics",
    volume="19",
    number="1",
    pages="1--67"  
}

@inproceedings{lenet,
    title="Gradient-Based Learning Applied to Document Recognition",
    author="Yann LeCun and Léon Bottou and Yoshua Bengio and Patrick Haffner",
    year="1998",
    booktitle="Proceedings of the IEEE"
    }

@manual{earth,
    title="Package ‘earth’",
    author="Stephen Milborrow",
    year="2016"
    }

@techreport{fastmars,
    author="Jerome H. Friedman",
    title="Fast MARS",
    institution="Department of Statistics, Stanford University",
    year="1993"}

@inproceedings{lrcn2014,
   Author = {Jeff Donahue and Lisa Anne Hendricks and Sergio Guadarrama
             and Marcus Rohrbach and Subhashini Venugopalan and Kate Saenko
             and Trevor Darrell},
   Title = {Long-term Recurrent Convolutional Networks
            for Visual Recognition and Description},
   Year  = {2015},
   Booktitle = {CVPR}
}

@phdthesis{chenyi_phd,
    author = "Chenyi Chen",
    school = "Princeton University",
    title = "Algorithmic Approaches to Extracting Cognition out of Images for the Purpose of Autonomous Driving",
    year = "2016"   
}

@manual{h2o,
    author={Spencer Aiello and Tom Kraljevic and Petr Maj},
    title="Package h2o",
    year="2015"
}

@inproceedings{bayesopt_paper,
    author = {Bobak Shahriari and Kevin Swersky and Ziyu Wang and Ryan P. Adams and Nando de Freitas},
    title = {Taking the Human Out of the Loop: A Review of Bayesian Optimization},
    howpublished = "\url{https://www.cs.ox.ac.uk/people/nando.defreitas/publications/BayesOptLoop.pdf}",
    organization="IEEE",
    year="2015"
}

@article{jia2014caffe,
  Author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
  Journal = {arXiv preprint arXiv:1408.5093},
  Title = {Caffe: Convolutional Architecture for Fast Feature Embedding},
  Year = {2014}
}

@article{rcpp,
    title = {{Rcpp}: Seamless {R} and {C++} Integration},
    author = {Dirk Eddelbuettel and Romain Fran\c{c}ois},
    journal = {Journal of Statistical Software},
    year = {2011},
    volume = {40},
    number = {8},
    pages = {1--18},
    url = {http://www.jstatsoft.org/v40/i08/},
}

@misc{bayesopt,
    title="BayesOpt",
    author="Ruben Martinez-Cantin",
    howpublished="\url{https://github.com/rmcantin/bayesopt}",
    year="2015"
}

@misc{statsmodels,
    title="statsmodels",
    author="Josef Perktold and Skipper Seabold and Jonathan Taylor",
    howpublished="\url{http://www.statsmodels.org/stable/index.html}",
    year="2009"
}

@misc{nolearn,
    title="nolearn",
    author="Daniel Nouri",
    howpublished="\url{https://github.com/dnouri/nolearn}",
    year="2012"
}

@misc{lasagne,
    title="lasagne",
    author="Sander Dieleman and Colin Raffel and Eben Olson and Jan Schlüter and Søren Kaae Sønderby",
    howpublished="\url{https://github.com/Lasagne/Lasagne}",
    year="2012"
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@INPROCEEDINGS{theano,
     author = {Bergstra, James and Breuleux, Olivier and Bastien, Fr{\'{e}}d{\'{e}}ric and Lamblin, Pascal and Pascanu, Razvan and Desjardins, Guillaume and Turian, Joseph and Warde-Farley, David and Bengio, Yoshua},
      month = jun,
      title = {Theano: a {CPU} and {GPU} Math Expression Compiler},
  booktitle = {Proceedings of the Python for Scientific Computing Conference ({SciPy})},
       year = {2010},
   location = {Austin, TX},
       note = {Oral Presentation},
   abstract = {Theano is a compiler for mathematical expressions in Python that combines the convenience of NumPy’s syntax with the speed of optimized native machine language. The user composes mathematical expressions in a high-level description that mimics NumPy’s syntax and semantics, while being statically typed and
functional (as opposed to imperative). These expressions allow Theano to provide symbolic differentiation. Before performing computation, Theano optimizes the choice of expressions, translates
them into C++ (or CUDA for GPU), compiles them into dynamically loaded Python modules, all automatically. Common machine learning algorithms implemented with Theano are from 1.6× to 7.5× faster than competitive alternatives (including those implemented with C/C++, NumPy/SciPy and MATLAB) when compiled for the
CPU and between 6.5× and 44× faster when compiled for the GPU. This paper illustrates how to use Theano, outlines the scope of the compiler, provides benchmarks on both CPU and GPU processors, and explains its overall design.}
}

@misc{py-earth,
    title="py-earth",
    author="Jason Rudy",
    howpublished="\url{https://github.com/scikit-learn-contrib/py-earth}",
    year="2013"
}